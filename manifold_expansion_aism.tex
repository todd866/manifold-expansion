\documentclass[smallextended,natbib,runningheads]{svjour3}
%
\journalname{Annals of the Institute of Statistical Mathematics}
%
\smartqed
%
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{float}

% Note: theorem, lemma, definition, remark, proposition, conjecture, proof
% are already defined by svjour3.cls

\begin{document}

\title{Communication Beyond Information: Manifold Expansion via High-Dimensional Coupling}

\titlerunning{Manifold Expansion via Coupling}

\author{Ian Todd}

\authorrunning{I. Todd}

\institute{I. Todd \at
           Sydney Medical School, University of Sydney \\
           Sydney, NSW, Australia \\
           \email{itod2305@uni.sydney.edu.au}
}

\date{Received: date / Revised: date}

\maketitle

\begin{abstract}
Many information-theoretic bounds assume a fixed statistical model class. We identify a regime where this assumption fails: when high-dimensional systems couple, the identifiable parameter set changes because the image rank of the dynamics-to-distribution map changes. We formalize this as \textit{manifold expansion}: coupling-induced increase in Fisher rank. Operationally, this means new score directions become nonzero---statistics that were previously insensitive to parameter variation become informative under coupling. Our main theorem provides checkable criteria for rank transitions: the \textit{transversality criterion} (coupling moves the accessible family off a constraint submanifold) and the \textit{symmetry-breaking criterion} (coupling breaks a group invariance). We prove Fisher rank equals Jacobian rank, so transitions are coordinate-invariant and detectable via eigenvalue emergence in the Fisher information matrix. Two examples demonstrate superadditive complexity: coupled Ornstein--Uhlenbeck processes (transversality, $\kappa_c = 0$) and Kuramoto oscillators (symmetry breaking, $\kappa_c > 0$).
\keywords{Fisher information metric \and Parameter identifiability \and Superadditivity \and Coupled dynamical systems \and Statistical manifolds}
\end{abstract}

%==============================================================================
\section{Introduction}
\label{intro}
%==============================================================================

Information theory provides powerful bounds on communication: channel capacity limits transmission rates, mutual information bounds learning, and data processing inequalities constrain inference \citep{cover2006elements}. Many commonly used bounds---PAC generalization, channel coding theorems, Cramér--Rao bounds---assume a fixed model class, channel law, or hypothesis space.

This assumption is usually invisible. When two agents exchange messages, we take for granted that the receiver's model class is fixed: decoding maps incoming symbols to a pre-existing internal space. Complexity growth is then bounded by how much information the channel can carry.

But what happens when the communicating systems are themselves high-dimensional dynamical objects? When a protocell network coordinates, or when coupled oscillators synchronize, or when interacting agents learn together---the systems don't merely exchange symbols. They \textit{reshape each other's dynamics}.

This paper identifies a regime where the fixed-manifold assumption need not hold, so that bounds derived for fixed model classes may underpredict complexity growth:

\begin{quote}
\textbf{Core claim}: When high-dimensional coherent systems couple, they exchange constraints rather than tokens. This can create new collective coordinates, increasing effective dimensionality beyond the sum of parts.
\end{quote}

We call this \textit{manifold expansion}: the accessible statistical manifold grows under coupling. This is not a violation of information theory---it is a regime where information theory's foundational assumption (fixed model class) need not hold.

The implications are significant:
\begin{itemize}
    \item Model complexity (identifiable dimensions) can grow faster than fixed-class bounds predict---because coupling activates new coordinates, not because information bounds are violated
    \item Communication becomes manifold deformation, not message passing
    \item The mechanism is scale-free: it applies wherever high-D systems interact
\end{itemize}

\subsection{The fixed-manifold assumption in practice}

To be precise about what we are \textit{not} claiming: we do not argue that data-processing inequalities are violated, or that channel capacity theorems fail. These results hold within their stated assumptions.

What we identify is a regime where the \textit{model class itself} changes under coupling, so that bounds derived for a fixed class can underpredict emergent complexity. The fixed-manifold assumption appears in several standard settings:

\begin{enumerate}
    \item \textbf{Generalization bounds}: PAC-learning and VC-dimension arguments assume a fixed hypothesis class $\mathcal{H}$. Sample complexity bounds scale with $\dim(\mathcal{H})$ \citep{cover2006elements}.

    \item \textbf{Channel capacity}: Shannon's theorem assumes a fixed channel law $p(y|x)$. Capacity is computed over this fixed conditional distribution.

    \item \textbf{Data processing inequalities}: DPI holds for fixed processing maps. If the map itself changes under interaction, DPI applies to each fixed map but not to the trajectory across maps.

    \item \textbf{Fisher information bounds}: Cramér-Rao and related bounds assume a fixed parametric family. If coupling changes which parameters are identifiable, the bounds shift.
\end{enumerate}

Our claim: \textit{coupling between high-dimensional systems can change the identifiable parameter set, so that applying bounds derived for a fixed family may underpredict the achievable complexity.}

To be explicit: we are tracking changes in the \textit{image dimension} of the parameter-to-distribution map, not claiming violations of information inequalities. The inequalities hold; what changes is the dimension of the family to which they apply.

\subsection{Coherence vs.\ information: the key distinction}
\label{sec:coherence}

We distinguish two conceptual modes of inter-system interaction that motivate our geometric framework:

\textit{Information transfer}: System $A$ transmits discrete, addressable, copyable tokens to system $B$. The receiver decodes tokens into a pre-existing internal representation. Complexity growth is bounded by channel capacity. This is the regime where standard information-theoretic bounds apply.

\textit{Constraint exchange}: System $A$ couples to system $B$ via shared dynamical modes. The coupling reshapes both systems' accessible state spaces. Complexity growth depends on geometric properties of the coupling, not channel capacity. This is the regime we study.

\textbf{High-dimensional coherent systems} (our focus) are those with: (i) many coupled internal degrees of freedom, (ii) long-lived collective modes or metastable states, and (iii) dynamics that maintain internal correlations over timescales longer than the coupling timescale. Examples include oscillator networks, neural populations, and coupled reaction systems near bifurcations.

The mathematical content of this paper concerns the constraint-exchange regime. We prove that coupling can increase the Fisher rank of an accessible family---a phenomenon invisible to channel-capacity arguments that assume a fixed model class.

\textbf{Scope clarification.} This is an \textit{identifiability/expressivity} claim, not a channel coding claim. We do not argue that mutual information through a coupling channel can exceed capacity bounds. Rather, we show that the \textit{dimension of the identifiable parameter family} can increase under coupling. A concrete illustration: two weakly coupled OU processes may exchange negligible mutual information through the coupling, yet the joint system's identifiable covariance structure has dimension 3 versus dimension 2 for the uncoupled system. The coupling activates a new statistically distinguishable coordinate (the cross-covariance) without requiring high-bandwidth information transfer.

\subsection{Paper outline}

This paper provides:
\begin{enumerate}
    \item \textbf{Section~\ref{sec:background}}: Background on information geometry and the fixed-manifold assumption
    \item \textbf{Section~\ref{sec:expansion}}: Formal setup---accessible families, collective coordinates, and the main theorem on coupling-induced rank transitions (Theorem~\ref{thm:main})
    \item \textbf{Section~\ref{sec:consequences}}: Consequences for complexity growth, including the complexity acceleration conjecture (Conjecture~\ref{conj:acceleration})
    \item \textbf{Section~\ref{sec:discussion}}: Discussion, testable predictions, and scope
\end{enumerate}

%==============================================================================
\section{Background: Information geometry}
\label{sec:background}
%==============================================================================

Information geometry studies the differential geometry of statistical manifolds \citep{amari2016information,ay2017information,nielsen2020elementary}. A statistical manifold $\mathcal{M}$ is a space of probability distributions, equipped with the Fisher information metric:
\begin{equation}
g_{ij}(\theta) = \mathbb{E}\left[ \frac{\partial \log p(x|\theta)}{\partial \theta_i} \frac{\partial \log p(x|\theta)}{\partial \theta_j} \right]
\end{equation}

The Fisher metric induces a Riemannian structure on $\mathcal{M}$. A key feature of information geometry is the existence of \textit{dual affine connections} ($\nabla^{(e)}$ and $\nabla^{(m)}$) corresponding to exponential and mixture geodesics. In dually flat manifolds (including exponential families), KL divergence is a canonical divergence whose second-order expansion recovers the Fisher metric, and information projections satisfy a Pythagorean theorem \citep{amari2016information}.

Communication and learning are naturally described as motion on this manifold:
\begin{itemize}
    \item Parameter estimation moves along geodesics (e- or m-geodesics depending on the estimation criterion)
    \item KL divergence locally approximates squared Fisher--Rao distance to second order
    \item Natural gradient descent follows the manifold's intrinsic geometry
    \item Information projections onto submanifolds minimize divergence
\end{itemize}

\textbf{The hidden assumption}: The manifold $\mathcal{M}$ is fixed. The parameterization $\theta$ may change, but the model class---the set of distributions considered---does not.

This assumption is reasonable when:
\begin{itemize}
    \item Systems have fixed, known structure
    \item Communication channels are well-defined
    \item Complexity is measured by localization on a fixed space
\end{itemize}

It can be inapplicable when:
\begin{itemize}
    \item Interacting systems are high-dimensional and adaptive
    \item Coupling creates new collective modes
    \item The model class itself is shaped by interaction
\end{itemize}

\subsection{Relation to hierarchical information geometry}

\citet{amari2001hierarchy}'s hierarchical decomposition of probability distributions provides the natural framework for our analysis. For a joint distribution $p(x_1, x_2)$, the log-linear decomposition separates marginal and interaction terms:
\begin{equation}
\log p(x_1, x_2) = \theta_1(x_1) + \theta_2(x_2) + \eta(x_1, x_2) + \psi
\end{equation}
where $\theta_1, \theta_2$ are marginal parameters and $\eta$ captures interactions. The \textit{independence submanifold} $\mathcal{M}_{\text{ind}}$ is the e-flat submanifold where $\eta = 0$.

\citet{amari2001hierarchy} showed that interaction coordinates $\eta$ are always \textit{structurally present} in the ambient model---they parameterize directions transverse to independence. Our contribution is orthogonal: we study when these coordinates become \textit{dynamically accessible}.

The distinction is crucial. In standard information geometry, one chooses a model class $\mathcal{M}$ and studies its geometry. The interaction coordinates either belong to $\mathcal{M}$ or they don't---this is a modeling choice. We consider a different situation: the dynamics determine which distributions are reachable, and coupling can change the reachable set. The ``manifold expansion'' we study is not a change in the chosen model, but a change in what the dynamics can produce.

This connects to recent work on sufficient statistics and statistical morphisms \citep{ay2015information}. The map from physical parameters to observable distributions is a statistical transformation; our rank-change theorems characterize when this transformation becomes more ``expressive'' under coupling.

\textbf{Relation to singular models.} Our focus on Fisher rank degeneracy connects to singular learning theory, where the Fisher information matrix is degenerate at certain parameter values \citep{watanabe2009algebraic}. In that literature, singularities are typically fixed features of a chosen model class. Here, the novelty is that degeneracy can be \textit{lifted by coupling}: parameter directions that are unidentifiable (in $\ker(dF_0)$) at zero coupling become identifiable (leave the kernel) at positive coupling. This ``identifiability activation'' is a dynamic phenomenon, not a property of a fixed model.

%==============================================================================
\section{Manifold expansion under coupling}
\label{sec:expansion}
%==============================================================================

\subsection{Setup: three distinct objects}

Consider two dynamical systems with state spaces $X_1 \subset \mathbb{R}^{n_1}$ and $X_2 \subset \mathbb{R}^{n_2}$. We distinguish three objects that are often conflated:

\begin{enumerate}
    \item \textbf{Ambient manifold} $\mathcal{P}(X_1 \times X_2)$: The space of all probability distributions over the joint state space. This is fixed.

    \item \textbf{Chosen model class} $\mathcal{M} \subset \mathcal{P}$: A parametric family the analyst uses for inference (e.g., ``all bivariate Gaussians''). Standard bounds assume this is fixed.

    \item \textbf{Accessible family} $\mathcal{M}_{\text{acc}}(\kappa)$: The distributions that the \textit{dynamics} can actually produce at coupling strength $\kappa$. This may change with $\kappa$.
\end{enumerate}

\textbf{The independence submanifold}: A key example of a submodel is $\mathcal{M}_{\text{ind}} = \{p_1 \otimes p_2 : p_i \in \mathcal{M}_i\}$---the product distributions with zero interaction. In information geometry terminology, this is an \textit{e-flat} submanifold corresponding to zero interaction coordinates in the hierarchical log-linear decomposition \citep{amari2016information}.

\textbf{The fixed-model assumption}: Many learning and communication bounds assume the accessible family is contained in a fixed model class. We do \textit{not} claim this assumption is wrong in general---only that it need not hold in the regime we study.

\textbf{Formal setup}: Let $\phi_\kappa: X_1 \times X_2 \to X_1 \times X_2$ denote coupled dynamics with coupling strength $\kappa \geq 0$, and let $h: X_1 \times X_2 \to \mathbb{R}^m$ be an observation map. Let $\mathcal{B}$ be a smooth $d$-dimensional manifold of \textit{physical parameters} $\beta$ (e.g., damping rates, noise intensities, frequencies).

\medskip
\noindent\fbox{\parbox{\dimexpr\linewidth-2\fboxsep-2\fboxrule}{%
\textbf{Key convention.} The coupling strength $\kappa$ is an \textit{index} selecting a dynamical system, not a coordinate in $\mathcal{B}$. This prevents trivial rank increases from simply adding $\kappa$ as a new parameter. Rank changes must arise from how coupling restructures the parameter$\to$distribution map, not from expanding the parameter space.}}
\medskip

\noindent For each fixed $\kappa$, we have a map:
\begin{equation}
F_\kappa: \mathcal{B} \to \mathcal{P}(\mathbb{R}^m), \quad \beta \mapsto Q_{(\kappa,\beta)} = (h)_\# P_{(\kappa,\beta)}
\end{equation}
where $P_{(\kappa,\beta)}$ is the stationary distribution of $\phi_\kappa$ at parameters $\beta$, and $(h)_\#$ denotes the pushforward through $h$. The \textit{accessible family} at coupling $\kappa$ is the image:
\[
\mathcal{M}_{\text{acc}}(\kappa) = \mathrm{Image}(F_\kappa) \subset \mathcal{P}(\mathbb{R}^m)
\]

\textbf{Role of the observation map.} The observation map $h: X_1 \times X_2 \to \mathbb{R}^m$ determines which features of the joint state are statistically accessible. When $h$ is the identity (full state observation), identifiability depends only on dynamics. When $h$ is a low-dimensional projection (partial observation), some coordinates may remain unidentifiable even if the dynamics distinguish them. Our rank-change theorems concern the map $F_\kappa = (h)_\# \circ P_{(\kappa,\cdot)}$; both dynamics and observation contribute to the accessible family. In the examples, we specify $h$ explicitly and note when identifiability depends on observation richness.

\textbf{Standing assumptions.} Throughout, we assume:
\begin{enumerate}
\item[(A1)] For each $(\kappa, \beta)$, the dynamics $\phi_\kappa$ admit a (locally) unique stationary distribution $P_{(\kappa,\beta)}$.
\item[(A2)] The map $\beta \mapsto P_{(\kappa,\beta)}$ (and hence $F_\kappa$) is smooth.
\item[(A3)] The observation map $h$ is smooth with sufficient regularity that $Q = (h)_\# P$ has a smooth density on its support.
\end{enumerate}
These assumptions exclude bifurcation points where stationary distributions split or vanish. Our results apply to parameter regions where (A1)--(A3) hold; analysis at bifurcation points requires additional care.

\textbf{Our claim}: For high-dimensional coherent systems, the rank of $dF_\kappa$ can increase as $\kappa$ crosses a threshold---the image manifold gains dimension.

\textbf{Technical note on dimensionality.} The ambient space $\mathcal{P}(\mathbb{R}^m)$ of all distributions is infinite-dimensional. For our purposes, we work locally inside a finite-dimensional parametric submanifold $\mathcal{P} \subset \mathcal{P}(\mathbb{R}^m)$ that contains the image of $F_\kappa$. This is the setting of classical information geometry: a \textit{regular} statistical manifold where the Fisher information metric is a nondegenerate inner product on each tangent space \citep{amari2016information}. Our results apply to the finite-dimensional accessible family $\mathcal{M}_{\text{acc}}(\kappa) = \text{Image}(F_\kappa) \subset \mathcal{P}$; we do not require the full machinery of infinite-dimensional information geometry.

\begin{definition}[Manifold expansion]
\label{def:expansion}
Define the \textit{generic rank} of $F_\kappa$ as:
\begin{equation}
r(\kappa) := \sup_{\beta \in \mathcal{B}} \mathrm{rank}\, dF_\kappa(\beta)
\end{equation}
By upper semicontinuity of rank (the sets $\{\beta : \mathrm{rank}\, dF_\kappa(\beta) \geq r\}$ are open for smooth maps), the set where rank equals the supremum is open. For analytic maps or generic smooth maps this set is also dense; in general applications we restrict to parameter regions where the supremum is attained. When $\mathcal{B}$ is compact, the supremum is a maximum.

\textbf{Manifold expansion} occurs at $\kappa_c$ if the generic rank increases as $\kappa$ crosses $\kappa_c$:
\begin{equation}
r(\kappa_c^+) > r(\kappa_c^-)
\end{equation}
Equivalently, the dimension of $\mathcal{M}_{\text{acc}}(\kappa)$ increases: a parameter direction in $\mathcal{B}$ that was generically in the kernel of $dF_\kappa$ becomes generically non-degenerate under coupling.

In Fisher-metric terms: manifold expansion corresponds to an increase in Fisher rank---the number of generically linearly independent score directions.
\end{definition}

This definition is coordinate-invariant: rank is preserved under reparameterization. It captures ``new identifiable directions appear'' in an intrinsic way.

The novelty is not that interaction parameters exist in the full parametric family---\citet{amari2001hierarchy}'s hierarchical decomposition already accounts for this. The novelty is that \textbf{dynamics and observation determine which interaction coordinates are identifiable}. Coupling can \textit{activate} coordinates that were structurally present but dynamically inaccessible---a phenomenon we term \textbf{coupling-induced identifiability activation}.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{figures/fig2_geometric_schematic.pdf}
\caption{\textbf{Geometric schematic of manifold expansion.} At $\kappa = 0$, the image of $F_0$ lies on the constraint submanifold $\mathcal{M}_0$. Under coupling ($\kappa > 0$), the image $F_\kappa(\mathcal{B})$ escapes into the transverse direction $\eta$, increasing Fisher rank by at least one.}
\label{fig:geometric}
\end{figure}

\subsection{Mechanism: collective coordinates}

Let $\phi: X_1 \times X_2 \to X_1 \times X_2$ be the coupled dynamics. Under coupling, new \textit{collective coordinates} can become accessible:

\begin{definition}[Collective coordinate]
A collective coordinate is a function $\psi: X_1 \times X_2 \to \mathbb{R}$ that is:
\begin{enumerate}
    \item Not reducible to functions of $X_1$ or $X_2$ alone
    \item \textit{Dynamically stable}: slow manifold, metastable basin, or conserved quantity
    \item \textit{Statistically identifiable}: non-degenerate Fisher information along $\psi$ under observation $h$
\end{enumerate}
\end{definition}

Examples:
\begin{itemize}
    \item Phase difference between coupled oscillators \citep{strogatz2000kuramoto,acebron2005kuramoto}
    \item Synchronization manifold coordinates \citep{pikovsky2001synchronization}
    \item Order parameters of collective states (e.g., chimera states) \citep{panaggio2015chimera}
    \item Interface modes at boundaries between systems
\end{itemize}

These coordinates represent genuinely new degrees of freedom: they were not accessible to either system in isolation.

\subsection{Main theorem: coupling-induced rank transitions}
\label{sec:main_theorem}

We now state and prove our main result, which provides checkable criteria for when coupling induces Fisher-rank transitions.

\textbf{Structure and novelty.} The theorem has three parts. Part I recalls the standard pullback characterization of Fisher information; we include it for completeness and to fix notation. \textbf{The novel content is Parts II and III}, which provide checkable criteria---in terms of kernel activation---for when coupling \textit{increases} the Fisher rank.

\begin{theorem}[Coupling-induced rank transitions]
\label{thm:main}
Let $\mathcal{B}$ be a smooth $d$-dimensional parameter manifold, let $\mathcal{P}$ be a finite-dimensional \textbf{regular} statistical manifold on observation space $Y$ equipped with the Fisher information metric $g$ (assumed positive-definite on each tangent space), and let $F_\kappa: \mathcal{B} \to \mathcal{P}$ be a smooth family of maps indexed by coupling strength $\kappa \geq 0$, where $F_\kappa(\beta) = Q_{(\kappa,\beta)}$ is the distribution of observations under dynamics with parameters $(\kappa, \beta)$.

\medskip
\noindent\textbf{Part I (Pullback identity).} The Fisher information matrix on $\mathcal{B}$ induced by the accessible family $\mathcal{M}_{\mathrm{acc}}(\kappa) = \mathrm{Image}(F_\kappa)$ is the pullback of the Fisher metric:
\begin{equation}
I_\mathcal{B}(\kappa) = F_\kappa^* g
\end{equation}
Consequently:
\begin{equation}
\mathrm{rank}\, I_\mathcal{B}(\kappa) = \mathrm{rank}\, dF_\kappa
\end{equation}

\medskip
\noindent\textbf{Part II (Transversality criterion).} Let $\mathcal{M}_0 \subset \mathcal{P}$ be a smooth submanifold of codimension $c$ (e.g., the independence submanifold). Choose local coordinates on $\mathcal{P}$ near $\mathcal{M}_0$ so that $\mathcal{M}_0 = \{\eta = 0\}$ locally, and write $F_\kappa(\beta) = (f_\kappa(\beta), \eta_\kappa(\beta))$ where $f$ are coordinates along $\mathcal{M}_0$ and $\eta$ are transverse coordinates. Let $\beta_0 \in \mathcal{B}$ achieve the maximal rank $r(0) = \mathrm{rank}\, dF_0(\beta_0)$. Suppose:
\begin{enumerate}
    \item[(C1)] $F_0(\mathcal{B}) \subseteq \mathcal{M}_0$, i.e., $\eta_0(\beta) \equiv 0$ (dynamics constrain to submanifold at $\kappa = 0$)
    \item[(C2)] \textbf{Kernel activation at $\beta_0$}: There exists $v \in T_{\beta_0}\mathcal{B}$ with $df_0(v) = 0$ (hence $v \in \ker(dF_0(\beta_0))$) such that $d\eta_\kappa|_{\beta_0}(v) \neq 0$ for $\kappa > \kappa_c$
\end{enumerate}
Geometrically, (C2) says $F_\kappa$ becomes transverse to $\mathcal{M}_0$ at $F_\kappa(\beta_0)$: the image acquires a component in the normal bundle $N\mathcal{M}_0$. Then for $\kappa > \kappa_c$:
\begin{equation}
r(\kappa) \geq r(0) + 1
\end{equation}

\medskip
\noindent\textbf{Part III (Symmetry-breaking criterion).} Let $G$ be a $k$-dimensional Lie group acting smoothly on $\mathcal{P}$, and let $\mathrm{Fix}(G) = \{p \in \mathcal{P} : \gamma \cdot p = p \text{ for all } \gamma \in G\}$ be the fixed-point set. Let $\beta_0 \in \mathcal{B}$ achieve the maximal rank $r(0) = \mathrm{rank}\, dF_0(\beta_0)$.

\textbf{Interpretation note.} When analyzing symmetry breaking, we work on the quotient $\mathcal{P}/G$ where the $G$-action has been quotiented out (equivalently, we gauge-fix by choosing a representative from each orbit). The rank increase arises because parameter directions in $\ker(dF_0)$ acquire nonzero images in the quotient geometry---typically via $G$-equivariant observables like order parameters that become parameter-sensitive when symmetry breaks.

Suppose:
\begin{enumerate}
    \item[(S1)] $F_0(\mathcal{B}) \subseteq \mathrm{Fix}(G)$ (distributions are $G$-invariant at $\kappa = 0$)
    \item[(S2)] For $\kappa > \kappa_c$, there exists $\beta$ such that $F_\kappa(\beta) \notin \mathrm{Fix}(G)$ (symmetry broken)
    \item[(S3)] \textbf{Kernel activation via symmetry breaking}: There exists $v \in \ker(dF_0(\beta_0))$ such that a $G$-invariant observable $\phi: \mathcal{P} \to \mathbb{R}$ (e.g., order parameter magnitude) satisfies $d(\phi \circ F_\kappa)|_{\beta_0}(v) \neq 0$ for $\kappa > \kappa_c$
\end{enumerate}
Then for $\kappa > \kappa_c$:
\begin{equation}
r(\kappa) \geq r(0) + 1
\end{equation}
More generally, if there are $k$ independent invariant observables activated, the rank increase is at least $k$.
\end{theorem}

\begin{proof}
\textbf{Part I.} Let $\beta(t)$ be a smooth curve in $\mathcal{B}$ with $\beta(0) = \beta_0$ and $\dot{\beta}(0) = v \in T_{\beta_0}\mathcal{B}$. The image curve $Q(t) = F_\kappa(\beta(t))$ has tangent vector $dF_\kappa(v) \in T_{Q_0}\mathcal{P}$.

The Fisher metric on $\mathcal{P}$ evaluates tangent vectors via score functions. By the chain rule:
\begin{equation}
\frac{\partial \log q(y; \kappa, \beta)}{\partial \beta^i} = \sum_\alpha \frac{\partial \log q}{\partial \theta^\alpha} \frac{\partial \theta^\alpha}{\partial \beta^i}
\end{equation}
where $\theta$ are coordinates on $\mathcal{P}$. The pullback metric is:
\begin{align}
(F_\kappa^* g)_{ij} &= g\left(\frac{\partial F_\kappa}{\partial \beta^i}, \frac{\partial F_\kappa}{\partial \beta^j}\right) = \left(I_\mathcal{B}(\kappa)\right)_{ij}
\end{align}
This establishes the pullback identity.

For the rank equality: the pullback metric $F_\kappa^* g$ is degenerate precisely along the kernel of $dF_\kappa$. A vector $v \in T_\beta \mathcal{B}$ satisfies $(F_\kappa^* g)(v, v) = 0$ if and only if $dF_\kappa(v) = 0$ (since $g$ is positive-definite on $T_Q\mathcal{P}$). Thus $\ker(I_\mathcal{B}(\kappa)) = \ker(dF_\kappa)$ and rank$(I_\mathcal{B}(\kappa)) = \mathrm{rank}\, dF_\kappa$.

\medskip
\textbf{Part II.} In local coordinates with $\mathcal{M}_0 = \{\eta = 0\}$, write $F_\kappa(\beta) = (f_\kappa(\beta), \eta_\kappa(\beta))$. At $\kappa = 0$, condition (C1) gives $\eta_0 \equiv 0$, so the image of $dF_0$ lies entirely in the $f$-directions with $\dim(\mathrm{Image}(dF_0(\beta_0))) = r(0)$.

Let $v \in \ker(df_0(\beta_0))$ be as in (C2). Since $\eta_0 \equiv 0$, we have $d\eta_0(v) = 0$, hence $dF_0(v) = (0, 0)$ and $v \in \ker(dF_0(\beta_0))$. By (C2), for $\kappa > \kappa_c$, $d\eta_\kappa|_{\beta_0}(v) \neq 0$, so $dF_\kappa(v)$ has a nonzero transverse component.

The tangent space decomposes as $T_p\mathcal{P} \cong T_p\mathcal{M}_0 \oplus N_p\mathcal{M}_0$. At $\kappa = 0$, the image of $dF_0$ lies entirely in $T\mathcal{M}_0$. The vector $dF_\kappa(v)$ has a nonzero component in $N\mathcal{M}_0$, so it is linearly independent of the $r(0)$ tangential directions. By continuity, the original $r(0)$ directions persist, so $r(\kappa) \geq r(0) + 1$.

\medskip
\textbf{Part III.} At $\kappa = 0$, (S1) implies $F_0(\mathcal{B}) \subseteq \mathrm{Fix}(G)$, so all $G$-invariant observables $\phi$ are constant on $F_0(\mathcal{B})$: varying $\beta$ does not change $\phi(F_0(\beta))$.

Let $v \in \ker(dF_0(\beta_0))$ and $\phi$ be as in (S3). At $\kappa = 0$, $dF_0(v) = 0$, so certainly $d(\phi \circ F_0)(v) = 0$. For $\kappa > \kappa_c$, condition (S3) states that $d(\phi \circ F_\kappa)|_{\beta_0}(v) \neq 0$.

Since $\phi$ is $G$-invariant, it descends to the quotient $\mathcal{P}/G$. The nonzero derivative $d(\phi \circ F_\kappa)(v)$ implies that $dF_\kappa(v)$ has a nonzero component in directions that affect $G$-invariant observables. This direction was in $\ker(dF_0)$ but leaves the kernel under coupling, giving $r(\kappa) \geq r(0) + 1$.
\end{proof}

\begin{corollary}[Operational detection of rank transitions]
\label{cor:detection}
Given time-series data at coupling strengths $\kappa_1 < \kappa_2 < \cdots < \kappa_m$, rank transitions can be detected as follows:
\begin{enumerate}
    \item \textbf{Estimate Fisher information}: For each $\kappa_j$, estimate the Fisher information matrix $\hat{I}(\kappa_j)$ from data---either directly via score function estimation, or via the Hessian of the log-likelihood at the MLE.
    \item \textbf{Track eigenvalues}: Compute eigenvalues $\lambda_1(\kappa_j) \geq \lambda_2(\kappa_j) \geq \cdots$ of $\hat{I}(\kappa_j)$.
    \item \textbf{Detect emergence}: A rank transition at $\kappa_c$ manifests as one or more eigenvalues crossing from $\lambda_k \approx 0$ (within estimation noise) to $\lambda_k > 0$ significantly.
\end{enumerate}
For the OU example, the minimal sufficient statistics are the sample covariance entries $(\hat{\Sigma}_{11}, \hat{\Sigma}_{22}, \hat{\Sigma}_{12})$; rank increase corresponds to $\hat{\Sigma}_{12}$ becoming $\beta$-sensitive. For Kuramoto, the order parameter magnitude $r$ and phase $\Psi$ suffice; rank increase corresponds to $\Psi$ becoming parameter-sensitive above $K_c$.
\end{corollary}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figures/fig1_eigenvalue_emergence.pdf}
\caption{\textbf{Eigenvalue emergence under coupling.} (A) Coupled Ornstein--Uhlenbeck: the third Fisher eigenvalue (correlation direction) emerges immediately at $\kappa > 0$. (B) Kuramoto oscillators: the phase-sensitivity eigenvalue emerges at the critical coupling $K_c$. Both demonstrate coupling-induced identifiability activation predicted by Theorem~\ref{thm:main}.}
\label{fig:eigenvalue}
\end{figure}

\subsection{Superadditive accessible complexity}
\label{sec:superadditive}

The preceding theorem establishes conditions for rank increase under coupling. We now formalize ``the whole exceeds the sum of its parts'' as a precise inequality.

\begin{definition}[Component accessible families]
For each subsystem $i = 1, \ldots, n$, let $\mathcal{B}_i$ be its parameter manifold and let $F_i: \mathcal{B}_i \to \mathcal{P}_i$ be its dynamics-to-distribution map. Define the component accessible family $\mathcal{M}_i := \mathrm{Image}(F_i)$ and its generic rank $r_i := \max_{\beta_i \in \mathcal{B}_i} \mathrm{rank}\, dF_i(\beta_i)$.
\end{definition}

\begin{definition}[Superadditive accessible complexity]
Let $F_\kappa: \mathcal{B} \to \mathcal{P}$ be the coupled dynamics-to-distribution map with generic rank $r(\kappa) := \max_{\beta \in \mathcal{B}} \mathrm{rank}\, dF_\kappa(\beta)$. The coupled system exhibits \textit{superadditive accessible complexity} at coupling $\kappa$ if
\[
r(\kappa) > r_{\oplus} = \sum_i r_i.
\]
\end{definition}

\begin{lemma}[Additivity under independence]
\label{lem:additivity}
For the independent composite map $F_{\oplus}$, $r_{\oplus} = \sum_{i=1}^n r_i$.
\end{lemma}

\begin{proof}
The differential $dF_{\oplus}$ is block-diagonal with blocks $dF_i$ on $T_{\beta_i}\mathcal{B}_i$. Hence $\mathrm{rank}\, dF_{\oplus}(\beta) = \sum_i \mathrm{rank}\, dF_i(\beta_i)$. Maximizing over $\beta$ yields $r_{\oplus} = \sum_i r_i$.
\end{proof}

\begin{proposition}[Sufficient condition via non-factorizable coordinates]
\label{prop:superadditive}
Suppose there exists a smooth map $\pi: \mathcal{P} \to \mathbb{R}^k$ such that:
\begin{enumerate}
\item[(A1)] $\pi \circ F_{\oplus}$ is locally constant on some open $U \subset \mathcal{B}$;
\item[(A2)] $\pi \circ F_\kappa$ has Jacobian rank $k$ on $U$.
\end{enumerate}
Then $r(\kappa) \geq r_{\oplus} + k$, so the coupled system is superadditive whenever $k \geq 1$.
\end{proposition}

\subsection{Example 1: coupled Ornstein--Uhlenbeck (transversality)}
\label{sec:ou}

This example demonstrates Theorem~\ref{thm:main} Part II (transversality criterion) with $\kappa_c = 0$.

\textbf{Dynamics.} Consider two coupled Ornstein--Uhlenbeck processes:
\begin{align}
dX_1 &= -\gamma_1 X_1 \, dt + \kappa(X_2 - X_1) \, dt + \sigma_1 \, dW_1 \\
dX_2 &= -\gamma_2 X_2 \, dt + \kappa(X_1 - X_2) \, dt + \sigma_2 \, dW_2
\end{align}
where $\gamma_i > 0$ are mean-reversion rates, $\sigma_i > 0$ are noise intensities, and $\kappa \geq 0$ is the coupling strength.

\textbf{Parameter manifold and observation.} The physical parameter manifold is $\mathcal{B} = \{(\gamma_1, \sigma_1, \gamma_2, \sigma_2) : \gamma_i > 0, \sigma_i > 0\} \cong (\mathbb{R}^+)^4$, which is 4-dimensional. The observation map is full state observation: $h(X_1, X_2) = (X_1, X_2)$, so the observable is the bivariate Gaussian with covariance $\Sigma$. The map $F_\kappa: \mathcal{B} \to \mathcal{P}$ sends $\beta = (\gamma_1, \sigma_1, \gamma_2, \sigma_2)$ to the centered bivariate Gaussian with covariance $\Sigma(\kappa, \beta)$. We compute the rank of the Jacobian $\partial(\Sigma_{11}, \Sigma_{22}, \Sigma_{12})/\partial\beta$.

\textbf{Stationary distribution.} The stationary distribution is bivariate Gaussian with zero mean and covariance matrix $\Sigma$ satisfying the Lyapunov equation $A\Sigma + \Sigma A^T + D = 0$. For the symmetric case $\gamma_1 = \gamma_2 = \gamma$ and $\sigma_1 = \sigma_2 = \sigma$:
\begin{align}
\Sigma_{11} = \Sigma_{22} &= \frac{\sigma^2(\gamma + \kappa)}{2\gamma(\gamma + 2\kappa)}, \qquad
\Sigma_{12} = \frac{\kappa \sigma^2}{2\gamma(\gamma + 2\kappa)}
\end{align}
giving correlation $\rho = \Sigma_{12}/\Sigma_{11} = \kappa/(\gamma + \kappa)$.

This confirms $\rho(\kappa=0) = 0$ and $\rho \to 1$ as $\kappa \to \infty$ (strong coupling induces perfect correlation, as expected physically). Computing $\partial\rho/\partial\gamma$:
\begin{equation}
\frac{\partial\rho}{\partial\gamma} = -\frac{\kappa}{(\gamma + \kappa)^2} \neq 0 \quad \text{for } \kappa > 0
\end{equation}
This nonzero derivative demonstrates kernel activation: a direction that left $\rho$ unchanged at $\kappa = 0$ now varies $\rho$ at $\kappa > 0$.

\textbf{Verification of Theorem~\ref{thm:main} Part II.} The ambient manifold $\mathcal{P}$ of centered bivariate Gaussians is 3-dimensional, parameterized by $(v_1, v_2, \rho)$. The independence submanifold is $\mathcal{M}_0 = \{(v_1, v_2, 0)\}$, which has codimension $c = 1$.

At $\kappa = 0$: $\rho = 0$ for all $\beta$, so $F_0(\mathcal{B}) \subseteq \mathcal{M}_0$ and $r(0) = 2$.

At $\kappa > 0$: $\rho > 0$, so $F_\kappa(\mathcal{B})$ escapes $\mathcal{M}_0$ and $r(\kappa) = 3$.

\textbf{Role of observation.} The rank increase from 2 to 3 assumes the observation map $h$ is rich enough to identify the cross-covariance $\Sigma_{12}$. If $h$ only observes $X_1$ (marginal observation), or only observes variances $(\Sigma_{11}, \Sigma_{22})$ without cross-terms, the correlation $\rho$ remains unidentifiable and the rank increase is not observable. This illustrates that both dynamics and observation contribute to the accessible family.

\textbf{Superadditivity.} Each OU process in isolation has a 1-dimensional accessible family (variance only), so $r_1 = r_2 = 1$ and $r_{\oplus} = 2$. The coupled system achieves $r(\kappa) = 3 > r_{\oplus} = 2$: \textit{strict superadditivity}.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figures/fig3_ou_covariance.pdf}
\caption{\textbf{Coupled OU: correlation emerges under coupling.} (A) The correlation $\rho = \kappa/(\gamma + \kappa)$ increases monotonically from zero, asymptoting to 1 as $\kappa \to \infty$. (B) Geometric interpretation: at $\kappa = 0$, the accessible family lies on the independence submanifold ($\rho = 0$); coupling moves the trajectory into the transverse direction.}
\label{fig:ou}
\end{figure}

\subsection{Example 2: Kuramoto synchronization (symmetry breaking)}
\label{sec:kuramoto}

This example demonstrates Theorem~\ref{thm:main} Part III (symmetry-breaking criterion) with $\kappa_c > 0$. We work in the \textbf{mean-field limit} ($N \to \infty$) with added noise, where the stationary density is unique up to symmetry \citep{strogatz2000kuramoto,acebron2005kuramoto}.

\textbf{Notation.} Following the Kuramoto literature, we denote coupling strength by $K$ (rather than $\kappa$) in this section. The role is identical: $K$ indexes the dynamical system, not a coordinate in the parameter space $\mathcal{B}$.

\textbf{Parameter space.} The physical parameter manifold is $\mathcal{B} = \{(D, \nu) : D > 0, \nu \in \mathcal{P}(\mathbb{R})\}$ where $D$ is noise intensity and $\nu$ is the frequency distribution. For concreteness, take $\nu = \mathcal{N}(\omega_0, \sigma_\omega^2)$ so that $\mathcal{B} \cong \mathbb{R}^+ \times \mathbb{R} \times \mathbb{R}^+$ is 3-dimensional. The mean phase $\Psi$ is \textit{not} a coordinate in $\mathcal{B}$---it parameterizes the $S^1$-orbit of solutions.

\textbf{Mean-field dynamics.} Let $\rho(\theta, \omega, t)$ be the density of oscillators with natural frequency $\omega$ at phase $\theta$. With phase diffusion of strength $D > 0$, the density evolves according to the nonlinear Fokker--Planck equation:
\begin{equation}
\frac{\partial \rho}{\partial t} + \frac{\partial}{\partial \theta}\left[\rho \left(\omega + Kr\sin(\Psi - \theta)\right)\right] = D \frac{\partial^2 \rho}{\partial \theta^2}
\end{equation}
where the order parameter $re^{i\Psi} = \int e^{i\theta} \rho(\theta, \omega, t) \, \nu(\omega) \, d\omega \, d\theta$ is determined self-consistently. The system has $S^1$ symmetry: if $\rho(\theta)$ is a solution, so is $\rho(\theta + \phi)$ for any $\phi$.

\textbf{Stationary solutions and gauge fixing.} For $K < K_c$, the unique stable stationary solution is the incoherent $S^1$-invariant density with $r = 0$. For $K > K_c$, there exists an $S^1$-\textit{orbit} of synchronized stationary solutions with $r > 0$. To satisfy assumption (A1), we define $F_K$ to return the \textbf{gauge-fixed representative} with $\Psi = 0$. Equivalently, one can define $F_K$ to return the equivalence class $[\rho]$ under $S^1$; the rank analysis is unchanged since we quotient by the symmetry.

\textbf{Verification of Theorem~\ref{thm:main} Part III.}
\begin{itemize}
\item (S1): For $K < K_c$, $F_K(\mathcal{B})$ is contained in the $S^1$-fixed point set (the incoherent state with $r = 0$).
\item (S2): For $K > K_c$, the synchronized stationary solutions have $r > 0$, breaking $S^1$ symmetry.
\item (S3) \textbf{Kernel activation via order parameter}: Consider varying the noise intensity $D$ or the frequency spread $\sigma_\omega$. For $K < K_c$, these parameters do not affect the (unique) incoherent distribution, so they lie in $\ker(dF_K)$. For $K > K_c$, these parameters affect the order parameter magnitude: $\partial r/\partial D \neq 0$ and $\partial r/\partial \sigma_\omega \neq 0$. The $S^1$-invariant observable $\phi = r$ becomes parameter-sensitive.
\end{itemize}

The theorem predicts: $r(K) \geq r(0) + 1$ for $K > K_c$. The ``$+1$'' comes from the order parameter magnitude becoming identifiable---a $G$-invariant observable that was constant on the incoherent manifold but varies with parameters on the synchronized manifold.

\textbf{Key difference from OU.} In the OU example (Part II), any $\kappa > 0$ immediately releases the constraint: $\kappa_c = 0$. In Kuramoto (Part III), the symmetry persists for $0 < K < K_c$; manifold expansion occurs at a \textit{genuine} critical threshold $K_c > 0$.

%==============================================================================
\section{Consequences for complexity growth}
\label{sec:consequences}
%==============================================================================

\subsection{Faster than fixed-class bounds predict}

Standard bounds on complexity growth assume fixed parameterization, fixed sufficient statistics, and fixed dimensionality.

When coupling creates new coordinates:
\begin{itemize}
    \item The Fisher geometry changes because the model class changes---new significant Fisher directions appear
    \item KL-based learning rates underpredict adaptation
    \item Channel capacity arguments don't apply (the ``channel'' itself is being restructured)
\end{itemize}

\begin{definition}[Model complexity]
We define \textit{complexity} $C$ of a statistical family $\mathcal{M}$ as the Fisher rank: the dimension of the identifiable tangent space. This is coordinate-invariant and intrinsic to the manifold geometry.

\textbf{Clarification.} Fisher rank measures \textit{identifiability dimension}---the number of statistically distinguishable directions---not computational or algorithmic complexity. We use ``complexity'' in the sense of ``accessible degrees of freedom under observation,'' following the information-geometric tradition where model dimension is a natural complexity measure \citep{amari2016information}.

\textbf{Rank vs.\ effective rank.} Fisher rank is a binary notion: a direction is either in the kernel (rank 0 contribution) or not (rank 1 contribution). It does not distinguish ``sloppy'' directions (small but nonzero eigenvalues) from ``stiff'' directions (large eigenvalues). In finite-sample settings, practical identifiability depends on whether eigenvalues exceed a noise floor. Our theoretical results concern the transition from $\lambda = 0$ to $\lambda > 0$; Conjecture~\ref{conj:acceleration} addresses the empirical signature via an $\epsilon$-threshold. For applications, one would use an \textit{effective rank} (e.g., number of eigenvalues above noise level) rather than exact rank.
\end{definition}

\begin{conjecture}[Eigenvalue emergence under coupling]
\label{conj:acceleration}
In regimes where the accessible family $\mathcal{M}_{\text{acc}}(\kappa)$ can be embedded in a fixed parameterization across $\kappa$, eigenvalue emergence provides a concrete signature. As coupling strength $\kappa$ crosses a critical threshold $\kappa_c$, one or more Fisher eigenvalues emerge from zero:
\begin{equation}
\lambda_k(\kappa_c^-) < \epsilon \quad \text{and} \quad \lambda_k(\kappa_c^+) > \epsilon
\end{equation}
This implies rank increase as coupling activates previously degenerate interaction coordinates.
\end{conjecture}

\subsection{Heuristic scaling: colony dynamics}

Consider $N$ high-D systems in a ``colony'' (weakly coupled network). The \textit{ambient space} of possible interaction parameters grows rapidly: with $N$ subsystems of internal dimension $n$, pairwise cross-covariances alone contribute $O(N^2 \cdot n^2)$ potential coordinates. However, the \textit{accessible} submanifold dimension is constrained by coupling parameters, symmetry constraints, attractor structure, and observation map.

A rough upper bound, if each pairwise coupling can create $k$ new identifiable coordinates:
\begin{equation}
\mathrm{rank}\, I_{\text{colony}} \leq N \cdot \mathrm{rank}\, I_{\text{single}} + |E| \cdot k
\end{equation}
where $|E|$ is the number of coupling edges. For dense networks $|E| \sim N^2$; for sparse networks $|E| \sim N$.

%==============================================================================
\section{Discussion}
\label{sec:discussion}
%==============================================================================

\subsection{Summary of contributions}

This paper provides:
\begin{enumerate}
    \item A formal definition of \textbf{manifold expansion} as Fisher-rank increase under coupling (Definition~\ref{def:expansion})
    \item \textbf{Theorem~\ref{thm:main}}: Coupling-induced rank transitions, with three parts:
    \begin{itemize}
        \item Part I: Pullback identity (Fisher rank = Jacobian rank)
        \item Part II: Transversality criterion for rank increase
        \item Part III: Symmetry-breaking criterion for rank increase
    \end{itemize}
    \item Worked examples verifying the theorem: coupled OU (Part II, $\kappa_c = 0$) and Kuramoto oscillators (Part III, $\kappa_c > 0$)
\end{enumerate}

The core technical contribution is identifying \textbf{coupling-induced identifiability activation}: interaction coordinates that are structurally present but dynamically inaccessible can become identifiable under coupling, increasing the Fisher rank of the observable family.

\subsection{Testable predictions}

The framework makes specific predictions:
\begin{enumerate}
    \item \textbf{Fisher rank increase}: For coupled dynamical systems, estimate Fisher information from time-series data at varying coupling strengths $\kappa$. Predict: $\mathrm{rank}\, I(\kappa)$ increases as $\kappa$ crosses critical thresholds.

    \item \textbf{Eigenvalue emergence}: New Fisher eigenvalues should emerge continuously from zero as coupling increases.

    \item \textbf{Superlinear scaling}: For colonies of $N$ coupled subsystems, the identifiable parameter count should grow faster than $N$ in the manifold-expansion regime.
\end{enumerate}

\subsection{Practical estimation protocol}
\label{sec:estimation}

We outline a concrete protocol for detecting manifold expansion from data.

\textbf{Setup.} Given time-series observations $\{y_t^{(\kappa)}\}_{t=1}^T$ at coupling strengths $\kappa \in \{\kappa_1, \ldots, \kappa_m\}$, the goal is to detect whether Fisher rank increases across the $\kappa$ sweep.

\textbf{Step 1: Choose sufficient statistics.} For each example:
\begin{itemize}
    \item \textit{Coupled OU}: Use sample covariance $\hat{\Sigma} = (\hat{\Sigma}_{11}, \hat{\Sigma}_{22}, \hat{\Sigma}_{12})$
    \item \textit{Kuramoto}: Use order parameter $(r, \Psi)$ estimated from phase time-series
    \item \textit{General}: Use moments or cumulants up to order matching the expected model dimension
\end{itemize}

\textbf{Step 2: Estimate Fisher information.} Two approaches:
\begin{enumerate}
    \item[(a)] \textit{Score-based}: Estimate partial derivatives $\partial_\beta \log p(y|\beta)$ at the MLE $\hat{\beta}$; compute $\hat{I}_{ij} = \frac{1}{T}\sum_t s_i(y_t) s_j(y_t)$ where $s_i = \partial_{\beta_i} \log p$.
    \item[(b)] \textit{Hessian-based}: Compute $\hat{I} = -\nabla^2_\beta \ell(\hat{\beta})$ where $\ell$ is the log-likelihood.
\end{enumerate}

\textbf{Step 3: Track eigenvalue spectrum.} For each $\kappa_j$, compute eigenvalues $\lambda_1 \geq \lambda_2 \geq \cdots$ of $\hat{I}(\kappa_j)$. Plot $\lambda_k(\kappa)$ versus $\kappa$.

\textbf{Step 4: Detect rank transition.} A rank increase at $\kappa_c$ appears as:
\begin{itemize}
    \item One or more eigenvalues crossing from $\lambda_k < \epsilon$ to $\lambda_k \gg \epsilon$
    \item The threshold $\epsilon$ should account for finite-sample noise (bootstrap confidence intervals recommended)
\end{itemize}

\textbf{Expected signatures by example:}
\begin{itemize}
    \item \textit{OU (transversality, $\kappa_c = 0$)}: The third eigenvalue (corresponding to $\Sigma_{12}$) emerges immediately at any $\kappa > 0$
    \item \textit{Kuramoto (symmetry breaking, $\kappa_c > 0$)}: An eigenvalue corresponding to phase sensitivity emerges at $K = K_c$, with the transition sharpening as system size increases
\end{itemize}

\subsection{Scope and limitations}

Our analysis assumes that the accessible family forms a smooth parametric model. In practice, the set of stationary distributions induced by dynamics may have irregular structure; our results apply where smooth-family regularity holds at least locally.

The mechanism is geometric, not substrate-specific. It applies wherever high-dimensional coherent systems couple and satisfy the regularity conditions of Theorem~\ref{thm:main}.

%==============================================================================
\section{Conclusion}
%==============================================================================

Information geometry has been remarkably successful because the fixed-manifold assumption usually holds. We have identified a regime where it does not: when high-dimensional coherent systems couple, the identifiable statistical family can expand.

This is not a rejection of information-theoretic bounds. It is recognition that such bounds apply to fixed model classes, and coupling can change which parameters are identifiable. The key contribution is formalizing this as \textbf{manifold expansion}---defined via Fisher-rank increase---and establishing conditions under which superadditive dimensionality occurs.

In the regime described here, a useful description is constraint exchange rather than token exchange: high-dimensional systems reshape each other's accessible state spaces rather than transmitting discrete symbols through a fixed channel.

\begin{acknowledgements}
The author thanks the anonymous reviewers for helpful comments.
\end{acknowledgements}

\section*{Statements and declarations}

\textbf{Funding.} The author did not receive support from any organization for the submitted work.

\textbf{Competing interests.} The author has no relevant financial or non-financial interests to disclose.

\textbf{Data availability.} No datasets were generated or analyzed. Simulation code is available at \url{https://github.com/todd866/manifold-expansion}

% Bibliography with author-year format
\begin{thebibliography}{99}

\bibitem[Acebrón et al.(2005)]{acebron2005kuramoto}
Acebrón, J.~A., Bonilla, L.~L., Pérez~Vicente, C.~J., Ritort, F., Spigler, R. (2005). The Kuramoto model: A simple paradigm for synchronization phenomena. \textit{Reviews of Modern Physics}, 77(1), 137--185

\bibitem[Amari(2001)]{amari2001hierarchy}
Amari, S.-I. (2001). Information geometry on hierarchy of probability distributions. \textit{IEEE Transactions on Information Theory}, 47(5), 1701--1711

\bibitem[Amari(2016)]{amari2016information}
Amari, S.-I. (2016). \textit{Information Geometry and Its Applications}. Springer

\bibitem[Ay et al.(2015)]{ay2015information}
Ay, N., Jost, J., Lê, H.~V., Schwachhöfer, L. (2015). Information geometry and sufficient statistics. \textit{Probability Theory and Related Fields}, 162(1), 327--364

\bibitem[Ay et al.(2017)]{ay2017information}
Ay, N., Jost, J., Lê, H.~V., Schwachhöfer, L. (2017). \textit{Information Geometry}. Springer

\bibitem[Cover and Thomas(2006)]{cover2006elements}
Cover, T.~M., Thomas, J.~A. (2006). \textit{Elements of Information Theory} (2nd ed.). Wiley

\bibitem[Nielsen(2020)]{nielsen2020elementary}
Nielsen, F. (2020). An elementary introduction to information geometry. \textit{Entropy}, 22(10), 1100

\bibitem[Panaggio and Abrams(2015)]{panaggio2015chimera}
Panaggio, M.~J., Abrams, D.~M. (2015). Chimera states: coexistence of coherence and incoherence in networks of coupled oscillators. \textit{Nonlinearity}, 28(3), R67--R87

\bibitem[Pikovsky et al.(2001)]{pikovsky2001synchronization}
Pikovsky, A., Rosenblum, M., Kurths, J. (2001). \textit{Synchronization: A Universal Concept in Nonlinear Sciences}. Cambridge University Press

\bibitem[Strogatz(2000)]{strogatz2000kuramoto}
Strogatz, S.~H. (2000). From Kuramoto to Crawford: exploring the onset of synchronization in populations of coupled oscillators. \textit{Physica D}, 143(1--4), 1--20

\bibitem[Watanabe(2009)]{watanabe2009algebraic}
Watanabe, S. (2009). \textit{Algebraic Geometry and Statistical Learning Theory}. Cambridge University Press

\end{thebibliography}

\end{document}
